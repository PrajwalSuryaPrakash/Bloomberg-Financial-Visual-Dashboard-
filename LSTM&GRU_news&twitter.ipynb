{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebf266-5269-4b85-b6a7-0b40600720c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b862f-e9b1-44bb-8920-e9760efef354",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bb545-edd3-4ec6-a81d-7ae22e704d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47acaeb-a3f4-4af4-ae9e-31d7b761dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --index-url=https://bcms.bloomberg.com/pip/simple blpapi\n",
    "#conda install -c conda-forge blpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e438e1-7e9b-459c-a56f-9103d74a7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xbbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e5b8f-5dd2-45cd-a7cf-a4c7b4cbcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "from xbbg import blp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error,accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Keras specific\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential,load_model, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, Bidirectional, BatchNormalization, Embedding, LSTM, Dense, GRU, Conv1D, GlobalMaxPool1D, MaxPool1D, MaxPooling1D, Dropout, Activation , Flatten , Input, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be4829-89fd-46d3-847e-4497e0b5870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = input(\"Enter the Equity name. eg: AAPL US Equity\\n\")\n",
    "#\"AAPL US Equity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722eb69-52da-4d63-ab16-39424c369bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = \"PX_LAST, PX_HIGH, PX_LOW, PX_VOLUME, TWITTER_SENTIMENT, TWITTER_NEG_SENTIMENT_COUNT, TWITTER_POS_SENTIMENT_COUNT, TWITTER_NEUTRAL_SENTIMENT_CNT, TWITTER_PUBLICATION_COUNT, NEWS_SENTIMENT_DAILY_AVG, NEWS_POS_SENTIMENT_COUNT, NEWS_NEG_SENTIMENT_COUNT, NEWS_NEUTRAL_SENTIMENT_COUNT, NEWS_PUBLICATION_COUNT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cde3d3-6acf-49a8-b8f4-72e7662b2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = input(\"Enter the start date in YYYY-MM-DD format\")\n",
    "#'2016-07-26'\n",
    "a=input(\"Type YES if you want current date as end date or no for custom date\")\n",
    " \n",
    "if a==\"YES\":\n",
    "    end=str(date.today())\n",
    "else:\n",
    "    end = str(input(\"Enter the end date in YYYY-MM-DD format\"))\n",
    "#'2021-07-26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ef0d5-32d9-4519-aa02-5e7d8bee5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = hashlib.md5(''.join((tickers,\"+\",\n",
    "          commands,\"+\",\n",
    "          start,\"+\",\n",
    "          end)).encode('utf-8')).hexdigest()\n",
    " \n",
    "if os.path.exists(filename+'.csv'):\n",
    "    data = pd.read_csv(filename+\".csv\", header=[0, 1],\n",
    "    parse_dates=True,\n",
    "    index_col=0)\n",
    "else:\n",
    "    data = blp.bdh(tickers=tickers.split(', ') , flds=commands.split(', '), start_date=start,  end_date=end,Per='D', Fill='P', Days='A', adjust='all')\n",
    "    data.to_csv(filename+\".csv\")\n",
    "   \n",
    "df = data[tickers]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbf501-73d0-4957-a71d-c63decf66a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated the technical indicators and also filling the null values in calculations using the bfill. Also made sure that the index is same for df and ti_df\n",
    "def get_technical_indicators(dataset):\n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset.loc[:, 'ma7'] = dataset['PX_LAST'].rolling(window=7).mean()\n",
    "    dataset.loc[:, 'ma21'] = dataset['PX_LAST'].rolling(window=21).mean()\n",
    "    # Create MACD\n",
    "    dataset.loc[:, '26ema'] = dataset['PX_LAST'].ewm(span=26).mean()\n",
    "    dataset.loc[:, '12ema'] = dataset['PX_LAST'].ewm(span=12).mean()\n",
    "    dataset.loc[:, 'MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "    # Create Bollinger Bands\n",
    "    dataset.loc[:, '20sd'] = dataset['PX_LAST'].rolling(20).std()\n",
    "    dataset.loc[:, 'upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
    "    dataset.loc[:, 'lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
    "    # Create Exponential moving average\n",
    "    dataset.loc[:, 'ema'] = dataset['PX_LAST'].ewm(com=0.5).mean()\n",
    "    # Create Momentum\n",
    "    dataset.loc[:, 'momentum'] = dataset['PX_LAST']-1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b38712-fd0d-4a82-a3e5-185b8aa62217",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_df = get_technical_indicators(df[['PX_LAST']].copy()).fillna(method='bfill')\n",
    "ti_df.index = pd.DatetimeIndex(df.index)\n",
    "ti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74979257-6656-42c8-894e-c1c7580d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target column\n",
    "target_column = ['PX_LAST']\n",
    "print(\"The target variable is PX_LAST\")\n",
    "# Define predictor columns\n",
    "predictors = list(set(list(df.columns)) - set(target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef7bf3-872a-46f0-a9c8-d26b45353694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ab7c6-09ad-472f-af1c-3da9c18e90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba57f50-1bc3-4656-9558-af71e3d3b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27ec9f-489f-4e99-99c5-a6d52ddd9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b5ba4-1186-492b-85d9-d7ac7210e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the features and transform them\n",
    "X_transformed = numerical_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2307f-32cb-4db9-b1a4-ea4d724e0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f283f18-59b2-44f6-a310-0f1bab1ced65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the target variable\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcbf71-18ee-4ae0-9639-42e2b01c45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_scaled, test_size=0.1, random_state=123, shuffle=False)\n",
    "split_time = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01dc93-f860-4504-9986-986163b11e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM/GRU input\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    " \n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851556f-a7d7-41b1-b9b4-69923b98315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "def create_lstm(X_train, regress=False):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=32, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=512))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef5c67-a4a7-42a6-adda-6e5b6bdce0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"./LSTM\"\n",
    "if not os.path.exists(modelName + \"/model.h5\"):\n",
    "    model_lstm = create_lstm(X_train, regress=False)\n",
    "    model_lstm.compile(loss='mae', optimizer='adam')\n",
    "    history_lstm = model_lstm.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "    scores_lstm = model_lstm.evaluate(X_train, y_train, verbose=0)\n",
    "    model_lstm.save(modelName + \".weights.h5\")\n",
    "    model_lstm.save_weights(modelName + \"model.weights.h5\")\n",
    "else:\n",
    "    model_lstm = load_model(modelName+ \".weights.h5\")\n",
    "    model_lstm.load_weights(modelName + 'model.weights.h5')\n",
    "    model_lstm.compile(loss='mae', optimizer='adam')\n",
    "    scores_lstm = model_lstm.evaluate(X_train, y_train, verbose=0)\n",
    " \n",
    "print(model_lstm.summary())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e7cf2-199a-4ed8-bcc0-f93da490a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model\n",
    "def create_gru(X_train, regress=False):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=32, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=512))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d3e01-86d5-40ec-9333-155f75823389",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"./GRU\"\n",
    "if not os.path.exists(modelName+\"/model.h5\"):\n",
    "    model_gru = create_gru(X_train, regress=False)\n",
    "    model_gru.compile(loss = 'mae', optimizer = 'adam')\n",
    "    history_gru = model_gru.fit(X_train, y_train, epochs = 15,batch_size=32, validation_data = (X_test, y_test), shuffle=False)\n",
    "    scores_gru = model_gru.evaluate(X_train, y_train, verbose=0)\n",
    "    model_gru.save(modelName + \".weights.h5\")\n",
    "    # serialize weights to HDF5\n",
    "    model_gru.save_weights(modelName+\"model.weights.h5\")\n",
    "else:    \n",
    "    model_gru = load_model(modelName + \".weights.h5\")\n",
    "    model_gru.load_weights(modelName+'model.weights.h5')\n",
    "    results_gru = model_gru.compile(loss = 'mae', optimizer = 'adam')\n",
    "    history_gru = model_gru.fit(X_train, y_train, epochs = 15,batch_size=32, validation_data = (X_test, y_test), shuffle=False)\n",
    "    scores_gru= model_gru.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "print(model_gru.summary())\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c5b7a-ae60-4993-90f1-c3a260dba4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    " \n",
    "y_predicted_lstm = model_lstm.predict(X_test)\n",
    "y_predicted_lstm = scaler.inverse_transform(y_predicted_lstm)\n",
    "y_predicted_lstm = pd.DataFrame(y_predicted_lstm)\n",
    " \n",
    "y_predicted_gru = model_gru.predict(X_test)\n",
    "y_predicted_gru = scaler.inverse_transform(y_predicted_gru)\n",
    "y_predicted_gru = pd.DataFrame(y_predicted_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eb6a6-0dfe-475b-8ade-dd3b76118c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for LSTM and GRU predictions\n",
    "mse_lstm = mean_squared_error(y_test, y_predicted_lstm)\n",
    "mse_gru = mean_squared_error(y_test, y_predicted_gru)\n",
    " \n",
    "# Calculate RMSE for LSTM and GRU predictions\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "rmse_gru = np.sqrt(mse_gru)\n",
    " \n",
    "# Print the evaluation metrics\n",
    "print(f\"LSTM Mean Squared Error (MSE): {mse_lstm}\")\n",
    "print(f\"LSTM Root Mean Squared Error (RMSE): {rmse_lstm}\")\n",
    "print(f\"GRU Mean Squared Error (MSE): {mse_gru}\")\n",
    "print(f\"GRU Root Mean Squared Error (RMSE): {rmse_gru}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40e10a-4173-45cf-a8ac-8e020fb65a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Virtualization\n",
    " \n",
    "color1 = \"#522dc2\"\n",
    "color2 = \"#daeb6c\"\n",
    "color3 = \"#c4c4be\"\n",
    " \n",
    "dfname = tickers\n",
    " \n",
    "#plotting last, high and low\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.plot(df['PX_LAST'][split_time:], lw=2, c=color1)\n",
    "plt.plot(df['PX_HIGH'][split_time:], lw=2, c=color2)\n",
    "plt.plot(df['PX_LOW'][split_time:], lw=2, c=color3)\n",
    "plt.legend(['Last','High', 'Low'])\n",
    " \n",
    "plt.title(dfname + ' - Data series')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9804c8-dfb8-4b47-a75d-7d99a22def9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting for last price, upper band and lower band\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.plot(ti_df['PX_LAST'][split_time:], lw=2, c=color1)\n",
    "plt.plot(ti_df['upper_band'][split_time:], lw=2, c=color2)\n",
    "plt.plot(ti_df['lower_band'][split_time:], lw=2, c=color3)\n",
    "plt.legend(['Last price','Upper band', 'Lower band'])\n",
    "plt.title(dfname + ' - Data series')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cffc0-1c42-47af-9107-51c585fb74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting for Last price\",\"7 days Moving Average\",\"21 days Moving Average\",\"12 days Exponential Moving Average\", \"26 days Exponential Moving Average\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.plot(ti_df['PX_LAST'][split_time:], lw=2, c=color1)\n",
    "plt.plot(ti_df['ma7'][split_time:], lw=2, c=color2)\n",
    "plt.plot(ti_df['ma21'][split_time:], lw=2)\n",
    "plt.plot(ti_df['12ema'][split_time:], lw=2 )\n",
    "plt.plot(ti_df['26ema'][split_time:], lw=2)\n",
    " \n",
    "plt.legend([\"Last price\",\"7 days Moving Average\",\"21 days Moving Average\",\"12 days Exponential Moving Average\", \"26 days Exponential Moving Average\"])\n",
    "plt.title(dfname + ' - Data series')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331876d4-8d29-428d-8ce5-990d45c808e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimisation\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    # Tune the number of units in the first LSTM layer\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=32), activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Tune the number of units in the second LSTM layer\n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=32, max_value=512, step=32), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Tune the number of units in the third LSTM layer\n",
    "    model.add(LSTM(units=hp.Int('units_3', min_value=32, max_value=512, step=32)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # The number of different hyperparameter combinations to try\n",
    "    executions_per_trial=1,  # Number of models to build and fit for each trial\n",
    "    directory='my_dir',\n",
    "    project_name='lstm_tuning'\n",
    ")\n",
    " \n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    " \n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c55f5b-1b2b-4bbe-866c-f5903ee4955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(hp):\n",
    "    model = Sequential()\n",
    "    # Tune the number of units in the first GRU layer\n",
    "    model.add(GRU(units=hp.Int('units_1', min_value=32, max_value=512, step=32), activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Tune the number of units in the second GRU layer\n",
    "    model.add(GRU(units=hp.Int('units_2', min_value=32, max_value=512, step=32), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Tune the number of units in the third GRU layer\n",
    "    model.add(GRU(units=hp.Int('units_3', min_value=32, max_value=512, step=32)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_gru_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # The number of different hyperparameter combinations to try\n",
    "    executions_per_trial=1,  # Number of models to build and fit for each trial\n",
    "    directory='my_dir',\n",
    "    project_name='gru_tuning'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca744a8-8372-4386-ba6e-5065d584f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
